ğŸ’» Laptop Price Prediction with Machine Learning
Predicting laptop prices using technical specifications and advanced regression techniques.




ğŸ“˜ Project Overview
This project focuses on building a machine learning model to predict laptop prices based on their technical specifications using a dataset sourced from Kaggle.

With over 1,200 entries and zero missing values, the dataset includes features such as:

- RAM

- CPU frequency

- Display type

- Operating system

 -Brand (60+ categories)

And more...

ğŸ§  Goals
- Perform regression modeling to predict laptop prices

- Engineer and encode features appropriately

- Compare multiple regression models and tune hyperparameters

- Visualize model performance

âš’ï¸ Key Challenges
- Encoding high-cardinality categorical features (e.g., 60+ laptop brands)

- Choosing the right encoding method: Label, One-Hot, Target, Ordinal

- Interpreting negative RMSE during cross-validation

- Balancing model complexity and interpretability

ğŸ“Š Models & Techniques Used
- Gradient Boosting Regressor (GBR) â€” best performance after tuning

- Linear Regression (baseline)

- Random Forest Regressor

- GridSearchCV for hyperparameter tuning

- Pipelines with scikit-learn

- Data visualization with matplotlib and seaborn

ğŸ“ˆ Performance
Metric	Value
- Initial RMSE	~183.12
- Tuned RMSE	~176.43

Fine-tuning the Gradient Boosting model significantly improved prediction accuracy.

ğŸ“ Project Structure
bash
ğŸ“¦ laptop-price-prediction/
â”œâ”€â”€ data/                   # Raw dataset (not included in repo)
â”œâ”€â”€ notebooks/              # Jupyter notebooks for EDA, modeling
â”œâ”€â”€ src/                    # Modular scripts for preprocessing, training
â”œâ”€â”€ models/                 # Saved models and tuning results
â”œâ”€â”€ README.md               # Project overview
â””â”€â”€ requirements.txt        # Python dependencies
ğŸ” Insights
- RAM and CPU frequency were strong predictors of price

- Display type and brand added nuance to price variation

- Feature engineering and encoding were crucial for performance

- Visualizing residuals helped uncover model limitations

ğŸš€ How to Run
Clone the repo:

bash
git clone https://github.com/Doyinakinloye/laptop-price-prediction.git
cd laptop-price-prediction
Create and activate a virtual environment:

bash

python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
Install dependencies:

bash

pip install -r requirements.txt
Run the notebook:

bash
Copy code
jupyter notebook notebooks/modeling.ipynb
ğŸ“š Dataset
Source: Kaggle Laptop Price Dataset

Note: Dataset not included due to licensing. Please download it manually.

ğŸ¤ Let's Connect!
Have questions about regression workflows, model tuning, or feature engineering?
Feel free to connect or reach out:

LinkedIn: www.linkedin.com/in/akinloye-oluwadoyinsolami-66b7a72b9

Email: doyinakinloye07@gmail.com

ğŸ·ï¸ Tags
#MachineLearning #Regression #FeatureEngineering #GradientBoosting #DataScience #Python #KaggleProject
